"""
é¦–é¡µã€Chatbotæ‚¬æµ®çª—å£ã€‘
1. æ•°æ®æµè½¬ -> æ•°æ®åº”ç”¨åœºæ™¯
2. å„åŠŸèƒ½æ¨¡å—ä»‹ç»å’Œè·³è½¬
3. ä¾§è¾¹æ ï¼šä»‹ç»ã€å­åŠŸèƒ½æ¨¡å—ã€ç­›é€‰å™¨ã€‘
"""
import os
from io import StringIO

import pandas as pd
import streamlit as st
from langchain.llms import OpenAI
from langchain.agents import create_pandas_dataframe_agent
from streamlit_chat import message
from streamlit_extras.colored_header import colored_header

from custom import *

st.set_page_config(page_title='AB-AutoGPT', layout='wide', page_icon='ğŸ¤–')
# è‡ªå®šä¹‰å…ƒç´ æ ·å¼
st.markdown(css_code, unsafe_allow_html=True)

os.environ['OPENAI_API_KEY'] = st.secrets['OPENAI_API_KEY']
# ä¾§è¾¹æ å†…å®¹
with st.sidebar:
    st.markdown("# ğŸ¤– AB-AutoGPT")
    st.markdown("### ã€0-1ã€‘é¢å‘AI/BigDataä»ä¸šè€…çš„AutoGPTï¼")
    st.write("---")

    st.write("\n")
    st.text_input("OpenAI API keyï¼š", key="set_chat_name", placeholder="ç‚¹å‡»è¾“å…¥")
    st.selectbox("é€‰æ‹©æ¨¡å‹ï¼š", index=0, options=['gpt-3.5-turbo', 'gpt-4'], key="select_model")
    st.write("\n")
    st.caption("""
    - åŒå‡»é¡µé¢å¯ç›´æ¥å®šä½è¾“å…¥æ 
    - Ctrl + Enter å¯å¿«æ·æäº¤é—®é¢˜
    """)
    st.markdown('<a href="https://github.com/typole/AB-AutoGPT" target="_blank" rel="ChatGPT-Assistant">'
                '<img src="https://badgen.net/badge/icon/GitHub?icon=github&amp;label=AB-AutoGPT" alt="GitHub">'
                '</a>', unsafe_allow_html=True)

    st.write("\n")
    st.write("---")
    st.markdown("### ğŸ“Š é€‰æ‹©æ•°æ®æº")
    st.write("\n")
    st.selectbox("æ•°æ®æºåŠ è½½ï¼š", index=0, options=['æœ¬åœ°æ–‡ä»¶[CSV]', 'MySQL', 'Hive', 'Doris'], key="select_data_source")
    if st.session_state['select_data_source'] == 'æœ¬åœ°æ–‡ä»¶[CSV]':
        def load_offline_csvfile():
            os.environ['OPENAI_API_KEY'] = st.secrets['OPENAI_API_KEY']

            uploaded_file = st.file_uploader("Choose a file")
            if uploaded_file is not None:
                # To read file as bytes:
                bytes_data = uploaded_file.getvalue()

                # To convert to a string based IO:
                stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))

                # To read file as string:
                string_data = stringio.read()

                # Can be used wherever a "file-like" object is accepted:
                return pd.read_csv(uploaded_file)


        data_obj = load_offline_csvfile()

st.write("\n")
st.header('AB-AutoGPT')
tap_example, tap_interactive = st.tabs(['ğŸ“° æ•°æ®ç¤ºä¾‹', 'ğŸ’¬ï¸ æ•°æ®äº¤äº’'])
with tap_example:
    if data_obj is not None:
        st.write(data_obj)
    else:
        st.write("è¯·å…ˆé€‰æ‹©æ•°æ®æºï¼")

with tap_interactive:
    # å°†æ¨¡å‹é€‰æ‹©ä¸ºï¼šmodel_name="gpt-3.5-turbo"
    if data_obj is not None:
        st.write("æ•°æ®æºå·²åŠ è½½ï¼å¼€å§‹ä½ çš„æ•°æ®æ¢ç´¢ä¹‹æ—…å§ï¼")
        # Generate empty lists for generated and past.
        # generated stores AI generated responses
        if 'generated' not in st.session_state:
            st.session_state['generated'] = ["æˆ‘æ˜¯ AB-AutoGPT, æœ‰ä»€ä¹ˆèƒ½å¤Ÿå¸®åŠ©ä½ å‘¢?"]
        # past stores User's questions
        if 'past' not in st.session_state:
            st.session_state['past'] = ['å“ˆå–½!']

        # Layout of input/response containers
        input_container = st.container()
        colored_header(label='', description='', color_name='blue-30')
        response_container = st.container()


        # User input
        # Function for taking user provided prompt as input
        def get_text():
            input_text = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜: ", "", key="input")
            return input_text


        # Applying the user input box
        with input_container:
            user_input = get_text()


        # Response output
        # Function for taking user prompt as input followed by producing AI generated responses
        def generate_response(prompt):
            agent = create_pandas_dataframe_agent(OpenAI(model_name="gpt-3.5-turbo", temperature=0), data_obj,
                                                  verbose=True)
            response = agent.run(prompt)
            return response


        # Conditional display of AI generated responses as a function of user provided prompts
        with response_container:
            if user_input:
                response = generate_response(user_input)
                st.session_state.past.append(user_input)
                st.session_state.generated.append(response)

            if st.session_state['generated']:
                for i in range(len(st.session_state['generated'])):
                    message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')
                    message(st.session_state["generated"][i], key=str(i))

    else:
        st.write("è¯·å…ˆé€‰æ‹©æ•°æ®æºï¼")
